{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMt5jDja9L4sKmMEw1/QHdB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/coldsober-irene/NLP-fellowship/blob/main/hackathon1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "VVznFQk0ndVF"
      },
      "outputs": [],
      "source": [
        "# REQUIRED IMPORTS\n",
        "from bs4 import BeautifulSoup as bs\n",
        "import requests\n",
        "import pandas as pd\n",
        "import re\n",
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# DATA MINING\n",
        "class dataMining:\n",
        "  def __init__(self, jobSource = \"Job In Rwanda\"):\n",
        "    self.source = jobSource\n",
        "    self.jobIdentification = {} # {\"software_developer\":[published_date, company, requirements, deadline, full_description],....}\n",
        "  \n",
        "  # SOUP\n",
        "  def Soup(self, url):\n",
        "    page = requests.get(url).content\n",
        "    soup = bs(page, \"html.parser\")\n",
        "    return soup\n",
        "\n",
        "  def get_links(self):\n",
        "    # GET SOUP OBJECT\n",
        "    soup = self.Soup(url = \"https://www.jobinrwanda.com/jobs/all\")\n",
        "    # GET ALL JOBS LINKS\n",
        "    company_infoLink = []\n",
        "    all_jobsLinks = [\"https://www.jobinrwanda.com\"+link['href'] if \"job\" in link['href'] else company_infoLink.append(\"https://www.jobinrwanda.com\"+link['href']) for div in soup.find_all(\"div\", class_= \"card-body p-2\") for link in div.find_all(\"a\")]\n",
        "    all_jobsLinks = [link for link in all_jobsLinks if link]\n",
        "    return (all_jobsLinks, company_infoLink)\n",
        "\n",
        "  def get_jobInfo(self):\n",
        "    jobLinks = self.get_links()[0]\n",
        "    info = []\n",
        "    # j = []\n",
        "    for url in jobLinks:\n",
        "      soup = self.Soup(url)\n",
        "      # job_info = [ul for div in soup.find('div', class_='card-body') for ul in div.find_all(\"ul\", class_ = \"list-group-flush\")]\n",
        "      pattern = re.compile(\"\\s{2,}\")\n",
        "      job_info = [pattern.sub(\" \",li.text.strip().replace(\"\\n\", \"\")) for ul in soup.find_all('ul', class_ = \"list-group list-group-flush\") for li in ul.find_all('li')]\n",
        "      # DICTIONANRY OF INFO\n",
        "      info.append(job_info[:9])\n",
        "    return info\n",
        "\n",
        "  def get_description(self):\n",
        "    jobLinks = self.get_links()[0]\n",
        "    all_text= []\n",
        "    for link in jobLinks:\n",
        "      soup = self.Soup(link)\n",
        "      tags_content = soup.find_all('div', class_= \"clearfix text-formatted field field--name-field-job-full-description field--type-text-long field--label-hidden field__item\")\n",
        "      for div in tags_content:\n",
        "        temp = []\n",
        "        for tag in div.children:\n",
        "          try:\n",
        "            temp.append(tag.get_text())\n",
        "          except AttributeError:\n",
        "            pass\n",
        "        all_text.append(temp)\n",
        "\n",
        "    return all_text\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "jobInRwanda = dataMining()\n",
        "# job_info = jobInRwanda.get_jobInfo()\n",
        "all_text = jobInRwanda.get_description()\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "FHrZBDzxnr2Q"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for text in all_text:\n",
        "  print(text[0])"
      ],
      "metadata": {
        "id": "MvLvTK4zmLyX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DATA SORTING"
      ],
      "metadata": {
        "id": "J_FyJUHenxcz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DATA PRESENTATION"
      ],
      "metadata": {
        "id": "OiOwDk__n0NH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}