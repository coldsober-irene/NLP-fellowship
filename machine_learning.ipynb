{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN+AUk2JH+N0S6Eu0xz0Jp2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/coldsober-irene/NLP-fellowship/blob/main/machine_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pEe5P6q9MRsQ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "# run plots in here without opening new window\n",
        "%matplotlib inline "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# mount\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "qCBXBM0kNpzy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = [\"/content/drive/MyDrive/NLP fellowship/self study/vgsales.csv\", \n",
        "           \"/content/drive/MyDrive/NLP fellowship/self study/music.csv\"]"
      ],
      "metadata": {
        "id": "Ukr1LktMMepX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# see the datasets\n",
        "df = pd.read_csv(dataset[1])"
      ],
      "metadata": {
        "id": "zUgr2A30OBlY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "QooyIU82Pcaw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# describe\n",
        "df.describe()"
      ],
      "metadata": {
        "id": "kxZb8i8-PhDD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check the data in a way similar to the csv\n",
        "df.values\n"
      ],
      "metadata": {
        "id": "ZD4gXSpdQHgp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check rows and columns (first rows and the second is the column)\n",
        "df.shape"
      ],
      "metadata": {
        "id": "p02FmwF2QUmn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "class me:\n",
        "  def __init__(self, name, age, weight):\n",
        "    self.name = name\n",
        "    self.age = age\n",
        "    self.weight = weight\n",
        "  \n",
        "  def display(self):\n",
        "    print(self.name)\n",
        "    print(self.age)\n",
        "    print(self.weight)\n",
        "\n",
        "# ob = me(\"irene\", 25, 65)\n",
        "# with open('irene.pickle', 'wb') as f:\n",
        "#   pickle.dump(ob, f)\n",
        "\n",
        "# read the object\n",
        "with open('irene.pickle', 'rb') as f:\n",
        "  my_obj = pickle.load(f)\n",
        "my_obj.display()"
      ],
      "metadata": {
        "id": "Q9_e05VhQxss"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**date 21st Jan 2022: self learning neural networking session**"
      ],
      "metadata": {
        "id": "YYSFSSiRROFO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# try to open some csv data\n",
        "path = \"\""
      ],
      "metadata": {
        "id": "qJnKQ6AbTZo4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# draft\n",
        "link = \"https://towardsdatascience.com/introduction-to-math-behind-neural-networks-e8b60dbbdeba\"\n",
        "from bs4 import BeautifulSoup as bs\n",
        "import requests\n",
        "\n",
        "full_text = \"\\n\".join([p.getText() for p in bs(requests.get(link).content, \"html.parser\").find_all('p')][3:-29])\n",
        "print(full_text)"
      ],
      "metadata": {
        "id": "Tl6l-fPgcuSh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load the data to be used"
      ],
      "metadata": {
        "id": "wY-Wf5brSHp0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# use logistic regression to get pred-machine learning usage"
      ],
      "metadata": {
        "id": "jSlT6pQxRutR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# generate random weights and bias"
      ],
      "metadata": {
        "id": "ebuw51RWRaR9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compute for consecutive weights and bias"
      ],
      "metadata": {
        "id": "E7Te5vw8RjkZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create a model"
      ],
      "metadata": {
        "id": "E7-gcQfiRqpc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train the model"
      ],
      "metadata": {
        "id": "xS_WUJuBR2tM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# display the output"
      ],
      "metadata": {
        "id": "JFiNpvz6R6wh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**IN-CLass work **"
      ],
      "metadata": {
        "id": "Lo23aVVSpLJQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_link = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\"\n",
        "# download the data\n",
        "data_downloaded = pd.read_csv(data_link)\n"
      ],
      "metadata": {
        "id": "wBDYMt8kpKLP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_downloaded"
      ],
      "metadata": {
        "id": "EmAN7I6PqX-y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = np.array(data_downloaded.iloc[:,0:8].astype('int')) # get all 8 coumns as train data\n",
        "test_data = np.array(data_downloaded.iloc[:,8].astype('int')) # get the last column as test data"
      ],
      "metadata": {
        "id": "OGLG1W1psz_C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define the model\n",
        "model = Sequential()"
      ],
      "metadata": {
        "id": "QrRySjW9t0Rz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# add alayer on your defined model\n",
        "# 12 is the number of nodes, input_shape: the shape of your input data, activation = \"relu\"\n",
        "\n",
        "# INPUT LAYER \n",
        "model.add(Dense(12, activation = 'relu', input_shape = (8,)))\n",
        "# 3 HIDDEN LAYERS\n",
        "model.add(Dense(8, activation = 'relu'))\n",
        "model.add(Dense(6, activation = 'relu'))\n",
        "model.add(Dense(6, activation = 'relu'))\n",
        "model.add(Dense(4, activation = 'relu'))\n",
        "model.add(Dense(2, activation = 'relu'))\n",
        "# OUTPUT LAYER\n",
        "model.add(Dense(1, activation = \"sigmoid\"))"
      ],
      "metadata": {
        "id": "aREqVYZft1SY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# COMPUTE THE LOSSES AND OPTIMIZE THOSE LOSSES\n",
        "model.compile(optimizer = \"adam\", loss = \"binary_crossentropy\", metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "mREQb5X67sPJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TRAIN THE MODEL\n",
        "# epochs: specifies how many times the model is going to learn the data\n",
        "# batch_size: number of rows the model is going to grab at once as it is sequential model\n",
        "\"\"\"\n",
        "once the model ends with grabbing all the batch size for the entire dataset to train, then we count one epoch\n",
        "\"\"\"\n",
        "model.fit(train_data, test_data, epochs = 1000, batch_size = 20)"
      ],
      "metadata": {
        "id": "txvjZ27N8eXM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check out the accuracy of your model\n",
        "_, accuracy = model.evaluate(train_data, test_data)"
      ],
      "metadata": {
        "id": "pPpD25Ir8l0C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#one-hot encoding example "
      ],
      "metadata": {
        "id": "ZUzXZ1xg1Dvy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"\"\"my name is irene nsengumukiza and this is the sentence for making the sample of the one hot encoding example\"\"\"\n",
        "words = text.split(\" \")\n",
        "vocab = set()\n",
        "for word in words:\n",
        "  if word not in vocab:\n",
        "    vocab.add(word)"
      ],
      "metadata": {
        "id": "xHXAQzXU1J8x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_index = {}\n",
        "index_word = {}\n",
        "for index, word in enumerate(words):\n",
        "  word_index[word] = index\n",
        "  index_word[index] = word\n"
      ],
      "metadata": {
        "id": "GTD_S9xt9vTK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "one_hot = np.zeros(shape=(len(vocab),len(words)), dtype = np.int64)"
      ],
      "metadata": {
        "id": "NLkCKQ4G2tGt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "one_hot"
      ],
      "metadata": {
        "id": "g6I7Owuf_2T5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index = 0\n",
        "for word in word_index.items():\n",
        "  one_hot[index][word[1]] = 1\n",
        "  index += 1\n",
        "  "
      ],
      "metadata": {
        "id": "4ZEGJYpJ3hiB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "one_hot"
      ],
      "metadata": {
        "id": "ujTX71zABmnM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(one_hot)"
      ],
      "metadata": {
        "id": "vXTOtCB5A69e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(len(words))"
      ],
      "metadata": {
        "id": "hGPi2dVOBNqy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#word2vec : word embedding"
      ],
      "metadata": {
        "id": "rtqnavokPAUm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = \"\"\"The future king is the prince\n",
        "Daughter is the princess in kingdom\n",
        "Son is the prince in the kingdom\n",
        "Only a man can be a king to rule the kingdom\n",
        "Only a woman can be a queen for the kingdom\n",
        "The princess will be a queen for the kingdom\n",
        "Queen and king rule the realm\n",
        "The prince is a strong man\n",
        "The princess is a beautiful woman\n",
        "The royal family is the king and queen and their children\n",
        "Prince is only a boy in the kingdom\n",
        "A boy will be a man in the future\"\"\".lower().split('\\n')"
      ],
      "metadata": {
        "id": "xXLA-v01O_yc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from spacy.lang.en import stop_words\n",
        "sw = stop_words.STOP_WORDS\n"
      ],
      "metadata": {
        "id": "oMk2mzrE7EBj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"the\" in sw"
      ],
      "metadata": {
        "id": "HFOWN4YsK7Wa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = [sentence.split() for sentence in sentences]"
      ],
      "metadata": {
        "id": "BEF6gfBK83CC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for sentence in tokens:\n",
        "  for stop in sw:\n",
        "    if stop in sentence:\n",
        "      sentence.remove(stop)"
      ],
      "metadata": {
        "id": "22byajnp85ed"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokens"
      ],
      "metadata": {
        "id": "7wXf7oTRI9A5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# text without stopwords\n",
        "uniques = set(\" \".join([\" \".join(row) for row in tokens]).split())"
      ],
      "metadata": {
        "id": "xyPbWQfRMgPd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# take the window size of 2\n",
        "w = 2\n",
        "\n",
        "combination = []\n",
        "count = 0\n",
        "done_at = 1\n",
        "for sentence in tokens:\n",
        "  for word in sentence:\n",
        "    if sentence.index(word) == 0:\n",
        "      combination.append([sentence[1], sentence[2]])\n",
        "    elif sentence.index(word) == 1:\n",
        "      combination.append([sentence[0], sentence[2]])\n",
        "    elif sentence.index(word) == len(sentence) - 1:\n",
        "      combination.append([sentence[-2], sentence[-3]])\n",
        "    else:\n",
        "      combination.append([sentence[sentence.index(word)-1], sentence[sentence.index(word)+1]])\n",
        "  count += 1"
      ],
      "metadata": {
        "id": "0tpiSjXlPuGC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "arr = np.array(combination)\n"
      ],
      "metadata": {
        "id": "5HehW_adrtdc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "arr"
      ],
      "metadata": {
        "id": "ZhASU5XSMNFp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "uniques = set(word for sentence in sentences for word in sentence.split(\" \") )"
      ],
      "metadata": {
        "id": "Iy9NYddfTpUB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "uniques"
      ],
      "metadata": {
        "id": "2HB9gSgz6h9W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create one hot encoding\n",
        "sample_arr = np.zeros(shape = (len(sentences),len(uniques)))"
      ],
      "metadata": {
        "id": "P-UqhXQCR-k7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "combination"
      ],
      "metadata": {
        "id": "tLMrfP9cQA3Z"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}