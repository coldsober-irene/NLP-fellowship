{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNrHSnEmqCpYSub0CznUngO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/coldsober-irene/NLP-fellowship/blob/main/Copy_of_hackathon1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "VVznFQk0ndVF"
      },
      "outputs": [],
      "source": [
        "# REQUIRED IMPORTS\n",
        "from bs4 import BeautifulSoup as bs\n",
        "import requests\n",
        "import pandas as pd\n",
        "import re\n",
        "import json\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# DATA MINING\n",
        "class dataMining:\n",
        "  def __init__(self, jobSource = \"Job In Rwanda\"):\n",
        "    self.source = jobSource\n",
        "    self.jobIdentification = {} # {\"software_developer\":[published_date, company, requirements, deadline, full_description],....}\n",
        "  \n",
        "  # SOUP\n",
        "  def Soup(self, url):\n",
        "    page = requests.get(url).content\n",
        "    soup = bs(page, \"html.parser\")\n",
        "    return soup\n",
        "\n",
        "  def get_links(self):\n",
        "    # GET SOUP OBJECT\n",
        "    soup = self.Soup(url = \"https://www.jobinrwanda.com/jobs/all\")\n",
        "    # GET ALL JOBS LINKS\n",
        "    company_infoLink = []\n",
        "    all_jobsLinks = [\"https://www.jobinrwanda.com\"+link['href'] if \"job\" in link['href'] else company_infoLink.append(\"https://www.jobinrwanda.com\"+link['href']) for div in soup.find_all(\"div\", class_= \"card-body p-2\") for link in div.find_all(\"a\")]\n",
        "    all_jobsLinks = [link for link in all_jobsLinks if link]\n",
        "    return (all_jobsLinks, company_infoLink)\n",
        "\n",
        "  def get_jobInfo(self):\n",
        "    jobLinks = self.get_links()[0]\n",
        "    info = {}\n",
        "    # REFINE THE INFO INTO A DICTIONARY\n",
        "    def refine_info(ls):\n",
        "      refined_info = {}\n",
        "      infoZeroPattern = re.compile(\"\\d+.*\")\n",
        "      views = infoZeroPattern.search(ls[0]).group()\n",
        "      refined_info[\"views\"] = views\n",
        "      # OTHER DETAILS EXCEPT THE ONE ON POSITION 0\n",
        "      otherInfoPattern = re.compile(\":\")\n",
        "      for detail in ls[1:]:\n",
        "        if detail.lower() == \"apply\":\n",
        "          pass\n",
        "        else:\n",
        "          try:\n",
        "            detailed = otherInfoPattern.split(detail)\n",
        "            refined_info[detailed[0]] = detailed[1]\n",
        "          except IndexError:\n",
        "            pass\n",
        "      return refined_info\n",
        "       \n",
        "    for index,url in enumerate(jobLinks):\n",
        "      soup = self.Soup(url)\n",
        "      pattern = re.compile(\"\\s{2,}\")\n",
        "      job_info = [pattern.sub(\" \",li.text.strip().replace(\"\\n\", \"\")) for ul in soup.find_all('ul', class_ = \"list-group list-group-flush\") for li in ul.find_all('li')]\n",
        "      # DICTIONANRY OF INFO\n",
        "      info[index] = refine_info(job_info[:9])\n",
        "    return info\n",
        "\n",
        "  def get_description(self):\n",
        "    jobLinks = self.get_links()[0]\n",
        "    all_text= {}\n",
        "    for index,link in enumerate(jobLinks):\n",
        "      soup = self.Soup(link)\n",
        "      tags_content = soup.find_all('div', class_= \"clearfix text-formatted field field--name-field-job-full-description field--type-text-long field--label-hidden field__item\")\n",
        "      \n",
        "      for div in tags_content:\n",
        "        temp = []\n",
        "        try:\n",
        "          # GET APPLICATION LINK\n",
        "          app_link = soup.find(\"a\", class_ = \"btn btn-sm btn-success\")['href']\n",
        "          if app_link.startswith(\"/\"):\n",
        "            app_link = \"https://www.jobinrwanda.com\"+app_link\n",
        "          temp.append(app_link)\n",
        "          # print(app_link)\n",
        "        except TypeError:\n",
        "          temp.append(np.nan)\n",
        "        for tag in div.children:\n",
        "          try:\n",
        "            temp.append(tag.get_text())\n",
        "          except AttributeError:\n",
        "            pass\n",
        "        all_text[index] = temp\n",
        "\n",
        "    return all_text\n"
      ],
      "metadata": {
        "id": "FHrZBDzxnr2Q"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WGCubCm58gEp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "jobInRwanda = dataMining()\n",
        "job_text = jobInRwanda.get_description()\n",
        "info = jobInRwanda.get_jobInfo()"
      ],
      "metadata": {
        "id": "ruesx8oF2J6K"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "info[10].values()"
      ],
      "metadata": {
        "id": "x8tV9C95-K-U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(job_text[2])"
      ],
      "metadata": {
        "id": "SlWQ_iweDrPQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MERGE JOB DESCRIPTION WITH THE JOB INFO\n",
        "for index in list(info.keys()):\n",
        "  info_value = list(info[index].values())\n",
        "  try:\n",
        "    info[index] = info_value.append(job_text[index][0]) # APPEND APPLICATION LINK\n",
        "    # job_text[index] = job_text[index].append(job_text[index][1:]) # JOB DESCRIPTION\n",
        "  except (AttributeError, TypeError):\n",
        "    print(job_text[index], index)"
      ],
      "metadata": {
        "id": "6M1vZYI28KaD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(job_text[10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_5zcKiNv-gCl",
        "outputId": "d921bc11-1636-4909-eb5f-8102640445b1"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# for infos in info[5]:\n",
        "#   print(infos)\n",
        "# all_text[50]\n",
        "info[40]"
      ],
      "metadata": {
        "id": "MvLvTK4zmLyX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6db4a5b-7717-4ac6-ebb6-b91702ed8e8c"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'views': '1751 times',\n",
              " 'Location': ' , RW',\n",
              " 'Sector': ' Administration, Business, Law, Other',\n",
              " 'Education level ': ' Bachelor',\n",
              " 'Desired experience': ' Entry level (1 to 3 years of experience)',\n",
              " 'Contract type ': ' Full-time',\n",
              " 'Deadline': ' Tuesday, 15/11/2022 17',\n",
              " 'Number of positions': ' 1'}"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pat = re.compile(\"\\d+.*\")\n",
        "pat.search(info[5][0]).group()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "55mMK7atwo2t",
        "outputId": "a19c01c0-b4d1-4c13-ede8-df487c5a2301"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1341 times'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# DATA SORTING"
      ],
      "metadata": {
        "id": "J_FyJUHenxcz"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DATA PRESENTATION"
      ],
      "metadata": {
        "id": "OiOwDk__n0NH"
      },
      "execution_count": 5,
      "outputs": []
    }
  ]
}